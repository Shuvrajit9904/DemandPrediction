{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn import preprocessing, model_selection, metrics\n",
    "import lightgbm as lgb\n",
    "\n",
    "color = sns.color_palette()\n",
    "%matplotlib inline\n",
    "\n",
    "#import plotly.offline as py\n",
    "#py.init_notebook_mode(connected=True)\n",
    "#import plotly.graph_objs as go\n",
    "#import plotly.tools as tls\n",
    "\n",
    "pd.options.mode.chained_assignment = None\n",
    "pd.options.display.max_columns = 999"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train file rows and columns are :  (1503424, 18)\n",
      "Test file rows and columns are :  (508438, 17)\n"
     ]
    }
   ],
   "source": [
    "train_df = pd.read_csv(\"data/train.csv\", parse_dates=[\"activation_date\"])\n",
    "test_df = pd.read_csv(\"data/test.csv\", parse_dates=[\"activation_date\"])\n",
    "print(\"Train file rows and columns are : \", train_df.shape)\n",
    "print(\"Test file rows and columns are : \", test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y = train_df[\"deal_probability\"].values\n",
    "test_id = test_df[\"item_id\"].values\n",
    "\n",
    "# New variable on weekday #\n",
    "train_df[\"activation_weekday\"] = train_df[\"activation_date\"].dt.weekday\n",
    "test_df[\"activation_weekday\"] = test_df[\"activation_date\"].dt.weekday\n",
    "\n",
    "# Label encode the categorical variables #\n",
    "cat_vars = [\"region\", \"city\", \"parent_category_name\", \"category_name\", \"user_type\", \"param_1\", \"param_2\", \"param_3\"]\n",
    "for col in cat_vars:\n",
    "    lbl = preprocessing.LabelEncoder()\n",
    "    lbl.fit(list(train_df[col].values.astype('str')) + list(test_df[col].values.astype('str')))\n",
    "    train_df[col] = lbl.transform(list(train_df[col].values.astype('str')))\n",
    "    test_df[col] = lbl.transform(list(test_df[col].values.astype('str')))\n",
    "\n",
    "cols_to_drop = [\"item_id\", \"user_id\", \"title\", \"description\", \"activation_date\", \"image\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = train_df.drop(cols_to_drop + [\"deal_probability\"], axis=1)\n",
    "test_X = test_df.drop(cols_to_drop, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_lgb(train_X, train_y, val_X, val_y, test_X):\n",
    "    params = {\n",
    "        \"objective\" : \"regression\",\n",
    "        \"metric\" : \"rmse\",\n",
    "        \"num_leaves\" : 30,\n",
    "        \"learning_rate\" : 0.1,\n",
    "        \"bagging_fraction\" : 0.7,\n",
    "        \"feature_fraction\" : 0.7,\n",
    "        \"bagging_frequency\" : 5,\n",
    "        \"bagging_seed\" : 2018,\n",
    "        \"verbosity\" : -1\n",
    "    }\n",
    "    \n",
    "    lgtrain = lgb.Dataset(train_X, label=train_y)\n",
    "    lgval = lgb.Dataset(val_X, label=val_y)\n",
    "    evals_result = {}\n",
    "    model = lgb.train(params, lgtrain, 1000, valid_sets=[lgval], early_stopping_rounds=100, verbose_eval=20, evals_result=evals_result)\n",
    "    \n",
    "    pred_test_y = model.predict(test_X, num_iteration=model.best_iteration)\n",
    "    return pred_test_y, model, evals_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1303424, 12) (200000, 12) (508438, 12)\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[20]\tvalid_0's rmse: 0.236221\n",
      "[40]\tvalid_0's rmse: 0.233507\n",
      "[60]\tvalid_0's rmse: 0.232136\n",
      "[80]\tvalid_0's rmse: 0.231493\n",
      "[100]\tvalid_0's rmse: 0.231028\n",
      "[120]\tvalid_0's rmse: 0.230668\n",
      "[140]\tvalid_0's rmse: 0.230338\n",
      "[160]\tvalid_0's rmse: 0.230086\n",
      "[180]\tvalid_0's rmse: 0.229867\n",
      "[200]\tvalid_0's rmse: 0.22968\n",
      "[220]\tvalid_0's rmse: 0.229557\n",
      "[240]\tvalid_0's rmse: 0.2294\n",
      "[260]\tvalid_0's rmse: 0.229287\n",
      "[280]\tvalid_0's rmse: 0.229155\n",
      "[300]\tvalid_0's rmse: 0.229047\n",
      "[320]\tvalid_0's rmse: 0.228926\n",
      "[340]\tvalid_0's rmse: 0.228818\n",
      "[360]\tvalid_0's rmse: 0.228743\n",
      "[380]\tvalid_0's rmse: 0.228671\n",
      "[400]\tvalid_0's rmse: 0.22859\n",
      "[420]\tvalid_0's rmse: 0.228505\n",
      "[440]\tvalid_0's rmse: 0.228418\n",
      "[460]\tvalid_0's rmse: 0.228355\n",
      "[480]\tvalid_0's rmse: 0.228291\n",
      "[500]\tvalid_0's rmse: 0.228261\n",
      "[520]\tvalid_0's rmse: 0.22821\n",
      "[540]\tvalid_0's rmse: 0.22815\n",
      "[560]\tvalid_0's rmse: 0.228073\n",
      "[580]\tvalid_0's rmse: 0.228022\n",
      "[600]\tvalid_0's rmse: 0.227969\n",
      "[620]\tvalid_0's rmse: 0.227926\n",
      "[640]\tvalid_0's rmse: 0.227887\n",
      "[660]\tvalid_0's rmse: 0.227844\n",
      "[680]\tvalid_0's rmse: 0.227804\n",
      "[700]\tvalid_0's rmse: 0.227766\n",
      "[720]\tvalid_0's rmse: 0.227738\n",
      "[740]\tvalid_0's rmse: 0.22771\n",
      "[760]\tvalid_0's rmse: 0.227664\n",
      "[780]\tvalid_0's rmse: 0.227633\n",
      "[800]\tvalid_0's rmse: 0.227592\n",
      "[820]\tvalid_0's rmse: 0.22755\n",
      "[840]\tvalid_0's rmse: 0.227526\n",
      "[860]\tvalid_0's rmse: 0.227489\n",
      "[880]\tvalid_0's rmse: 0.227456\n",
      "[900]\tvalid_0's rmse: 0.227423\n",
      "[920]\tvalid_0's rmse: 0.227385\n",
      "[940]\tvalid_0's rmse: 0.227356\n",
      "[960]\tvalid_0's rmse: 0.22732\n",
      "[980]\tvalid_0's rmse: 0.227303\n",
      "[1000]\tvalid_0's rmse: 0.227271\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\tvalid_0's rmse: 0.227271\n"
     ]
    }
   ],
   "source": [
    "# Splitting the data for model training#\n",
    "dev_X = train_X.iloc[:-200000,:]\n",
    "val_X = train_X.iloc[-200000:,:]\n",
    "dev_y = train_y[:-200000]\n",
    "val_y = train_y[-200000:]\n",
    "print(dev_X.shape, val_X.shape, test_X.shape)\n",
    "\n",
    "# Training the model #\n",
    "pred_test, model, evals_result = run_lgb(dev_X, dev_y, val_X, val_y, test_X)\n",
    "\n",
    "# Making a submission file #\n",
    "pred_test[pred_test>1] = 1\n",
    "pred_test[pred_test<0] = 0\n",
    "sub_df = pd.DataFrame({\"item_id\":test_id})\n",
    "sub_df[\"deal_probability\"] = pred_test\n",
    "sub_df.to_csv(\"baseline_lgb.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
