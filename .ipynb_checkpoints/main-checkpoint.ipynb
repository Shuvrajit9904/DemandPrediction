{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shuvrajit/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn import preprocessing, model_selection, metrics\n",
    "import lightgbm as lgb\n",
    "\n",
    "\n",
    "import sys, os, re, csv, codecs, numpy as np, pandas as pd\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Dense, Input, LSTM, Embedding, Dropout, Activation\n",
    "from keras.layers import Bidirectional, GlobalMaxPool1D\n",
    "from keras.models import Model\n",
    "from keras import initializers, regularizers, constraints, optimizers, layers\n",
    "\n",
    "color = sns.color_palette()\n",
    "%matplotlib inline\n",
    "pd.options.mode.chained_assignment = None\n",
    "pd.options.display.max_columns = 999"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train file rows and columns are :  (1503424, 18)\n",
      "Test file rows and columns are :  (508438, 17)\n"
     ]
    }
   ],
   "source": [
    "train_df = pd.read_csv(\"data/train.csv\", parse_dates=[\"activation_date\"])\n",
    "test_df = pd.read_csv(\"data/test.csv\", parse_dates=[\"activation_date\"])\n",
    "print(\"Train file rows and columns are : \", train_df.shape)\n",
    "print(\"Test file rows and columns are : \", test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y = train_df[\"deal_probability\"].values\n",
    "test_id = test_df[\"item_id\"].values\n",
    "\n",
    "# New variable on weekday #\n",
    "train_df[\"activation_weekday\"] = train_df[\"activation_date\"].dt.weekday\n",
    "test_df[\"activation_weekday\"] = test_df[\"activation_date\"].dt.weekday\n",
    "\n",
    "# Label encode the categorical variables #\n",
    "cat_vars = [\"region\", \"city\", \"parent_category_name\", \"category_name\", \"user_type\", \"param_1\", \"param_2\", \"param_3\"]\n",
    "for col in cat_vars:\n",
    "    lbl = preprocessing.LabelEncoder()\n",
    "    lbl.fit(list(train_df[col].values.astype('str')) + list(test_df[col].values.astype('str')))\n",
    "    train_df[col] = lbl.transform(list(train_df[col].values.astype('str')))\n",
    "    test_df[col] = lbl.transform(list(test_df[col].values.astype('str')))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_drop = [\"item_id\", \"user_id\", \"title\", \"activation_date\", \"image\"]\n",
    "train_X = train_df.drop(cols_to_drop + [\"deal_probability\"], axis=1)\n",
    "test_X = test_df.drop(cols_to_drop, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating Word Vector for Description\n",
    "EMBEDDING_FILE = f'wiki.ru.vec'\n",
    "embed_size = 300\n",
    "max_features = 20000\n",
    "maxlen = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_sentences_train = train_X['description'].fillna('_na_').values\n",
    "tokenizer = Tokenizer(num_words=max_features)\n",
    "tokenizer.fit_on_texts(list(list_sentences_train))\n",
    "list_tokenized_train = tokenizer.texts_to_sequences(list_sentences_train)\n",
    "X_train = pad_sequences(list_tokenized_train, maxlen = maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def get_coefs(word,*arr): return word, np.asarray(arr, dtype='float32')\n",
    "#embeddings_index = dict(get_coefs(o.strip().split()[0], *o.strip().split()[1:]) for o in open(EMBEDDING_FILE))\n",
    "embedding_index = {}\n",
    "for o in open(EMBEDDING_FILE):\n",
    "    vec = o.strip().split(' ')\n",
    "    word = vec[0]\n",
    "    arr = np.asarray(vec[1:], dtype='float32')\n",
    "    embedding_index[word] = arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1888423', '300']\n",
      "['</s>', '0.0052262', '0.20497', '0.096731', '0.047762', '0.04126', '0.055935', '-0.039348', '-0.14709', '0.15184', '0.17101', '-0.018269', '0.096936', '0.22801', '0.10778', '-0.09184', '-0.36971', '-0.15413', '-0.32771', '0.26368', '0.42271', '0.25759', '0.012656', '-0.26443', '-0.07946', '0.032226', '-0.42462', '0.12959', '0.015581', '-0.1945', '-0.16886', '-0.08058', '-0.11546', '0.254', '-0.10331', '-0.04658', '0.092436', '-0.34151', '-0.10176', '-0.077935', '0.26197', '-0.12292', '0.097782', '0.012892', '0.015233', '0.07506', '0.013053', '-0.10969', '0.053725', '0.04215', '0.15373', '0.052467', '0.27102', '0.20063', '-0.17201', '0.42024', '0.20941', '0.17578', '0.060628', '0.17401', '-0.20136', '-0.10175', '-0.27376', '0.021373', '0.055022', '0.20643', '0.31438', '-0.18813', '-0.18306', '0.23244', '-0.099184', '0.03191', '0.010869', '0.1723', '-0.11144', '-0.0047661', '-0.12414', '-0.079561', '0.16612', '0.40702', '-0.14031', '0.25533', '0.22604', '0.24683', '0.036313', '0.26846', '-0.23714', '0.045032', '-0.078741', '-0.18594', '-0.21385', '0.017894', '-0.040911', '0.24713', '-0.23265', '-0.26126', '-0.45927', '0.17232', '0.12445', '-0.057269', '-0.30443', '-0.025849', '-0.034554', '0.2186', '-0.39458', '0.21842', '-0.029222', '-0.064034', '-0.16905', '-0.14331', '0.013372', '-0.093132', '0.1389', '-0.37926', '0.042186', '-0.093006', '0.18836', '0.16086', '-7.4083e-05', '-0.186', '0.35898', '-0.15218', '-0.17821', '0.034776', '0.017891', '0.091534', '-0.54505', '0.17465', '0.30014', '0.23949', '-0.01545', '0.058121', '-0.12358', '-0.30544', '-0.35149', '0.093686', '0.30039', '0.050947', '-0.33992', '0.098403', '-0.0034018', '-0.30297', '-0.091155', '-0.079147', '0.1927', '0.14989', '-0.20975', '0.06353', '0.3793', '0.23341', '0.068017', '0.14282', '-0.085547', '0.23531', '0.17433', '-0.38914', '0.092116', '-0.14405', '-0.018843', '0.17375', '0.49286', '-0.12183', '0.1573', '0.073169', '-0.13614', '-0.32171', '0.015624', '-0.05123', '-0.12328', '-0.16624', '-0.24556', '-0.16515', '-0.23225', '0.027728', '0.072595', '0.070104', '0.30645', '-0.030132', '0.067924', '-0.056855', '0.0079078', '0.016437', '-0.28803', '-0.15075', '0.039725', '-0.093682', '-0.32709', '-0.036521', '0.15631', '0.24633', '0.13835', '0.0011218', '-0.28558', '0.065427', '-0.028636', '-0.1371', '0.00088804', '0.0048655', '-0.020291', '-0.020867', '0.016382', '-0.10225', '0.27868', '-0.069495', '-0.082583', '0.16745', '0.032385', '0.24554', '0.044596', '-0.25652', '0.27856', '-0.068624', '-0.20344', '-0.24863', '0.013681', '-0.24064', '-0.086573', '-0.22418', '-0.014525', '-0.2066', '-0.30948', '0.16639', '0.22678', '0.18541', '-0.3128', '-0.48496', '0.19731', '-0.27976', '-0.069052', '-0.23521', '0.22285', '-0.1239', '-0.062618', '-0.2257', '0.28036', '-0.21291', '0.076903', '-0.02008', '-0.0098709', '0.13988', '-0.25872', '-0.24999', '0.16411', '-0.11136', '-0.047973', '0.35095', '-0.20351', '0.1038', '-0.23494', '-0.022816', '0.19937', '0.062047', '-0.25782', '0.11735', '0.11933', '0.056101', '0.1757', '-0.067542', '0.18727', '-0.50915', '-0.15683', '-0.071516', '-0.33092', '-0.2676', '0.37494', '-0.44945', '0.068777', '0.30343', '-0.30631', '0.20572', '-0.15065', '-0.095521', '-0.22067', '0.18668', '0.038424', '-0.073479', '0.015091', '0.1211', '0.10641', '-0.17399', '-0.0096287', '-0.15671', '0.21019', '0.080452', '-0.30442', '-0.048548', '0.29573', '0.13182', '0.0048994', '-0.011153', '0.16913', '0.053786', '0.039093', '-0.35015', '0.059035', '0.47813', '-0.037452', '-0.038522', '0.16528', '-0.44632', '0.10176']\n",
      "[',', '-0.28093', '0.19175', '-0.15895', '0.19725', '0.12523', '0.16079', '-0.047091', '0.11082', '0.089318', '0.11542', '0.18068', '0.16955', '0.13498', '0.22797', '-0.12574', '-0.015891', '-0.142', '-0.15412', '0.14878', '0.24787', '0.19433', '0.13279', '-0.2539', '-0.016595', '-0.051814', '0.1136', '-0.15559', '0.22163', '-0.097685', '-0.13399', '-0.0091268', '0.017945', '-0.019017', '-0.17926', '-0.06454', '0.023392', '-0.0008628', '-0.31956', '0.082736', '-0.12347', '0.15652', '-0.088902', '-0.16538', '-0.076986', '-0.015768', '-0.0028525', '-0.0095446', '0.16051', '-0.12104', '-0.11946', '0.03612', '-0.20852', '-0.070691', '0.059959', '0.23927', '-0.11384', '-0.067404', '0.03607', '0.10908', '-0.011748', '0.20424', '-0.094594', '0.16272', '0.22818', '0.083903', '0.096003', '0.1217', '0.057304', '-0.13292', '-0.0087459', '0.17896', '0.043712', '0.014902', '0.013989', '-0.071298', '-0.15912', '0.05507', '0.090795', '0.101', '-0.11038', '-0.043771', '0.15126', '-0.085222', '-0.076035', '0.13034', '-0.081618', '0.027284', '0.040206', '-0.18299', '0.04988', '-0.12258', '-0.16707', '-0.033355', '-0.1554', '-0.18691', '-0.084747', '-0.077556', '-0.017064', '0.088538', '-0.053862', '-0.0044269', '-0.057472', '-0.17257', '-0.28644', '0.15842', '0.035698', '-0.042293', '-0.066119', '-0.11429', '0.31608', '0.24836', '-0.063061', '-0.15887', '0.17204', '0.02445', '0.063906', '0.084421', '0.13154', '-0.076542', '-0.10613', '0.033608', '-0.10956', '0.052576', '0.028358', '-0.0065281', '0.10765', '0.11036', '0.11139', '0.26197', '0.19645', '0.04244', '-0.098685', '-0.10834', '-0.0037885', '-0.02132', '0.15994', '-0.13002', '-0.051327', '0.12717', '-0.14482', '0.036196', '-0.058063', '0.31729', '0.14658', '-0.039214', '-0.13612', '-0.23742', '0.051872', '-0.061959', '-0.13825', '-0.11433', '-0.2603', '-0.053012', '0.061106', '0.022329', '-0.038115', '0.003482', '-0.12086', '-0.059964', '0.18393', '-0.20409', '0.13875', '0.11499', '-0.036018', '0.025295', '-0.032851', '0.0087357', '-0.0010847', '-0.10112', '0.085231', '-0.17577', '-0.027629', '-0.032081', '0.040108', '0.016245', '-0.16306', '-0.017402', '0.10611', '0.013035', '-0.047615', '-0.0085305', '-0.066407', '-0.17879', '0.0076254', '-0.21158', '-0.04275', '0.01463', '0.020243', '0.037569', '-0.024383', '-0.048889', '-0.11118', '0.043114', '-0.24636', '-0.059534', '-0.18148', '-0.22454', '-0.1676', '-0.18693', '0.013617', '-0.16138', '-0.069596', '0.13834', '0.014051', '0.20596', '0.004968', '0.06834', '-0.0077858', '0.20397', '0.0052329', '-0.13992', '-0.03264', '-0.004475', '-0.0073177', '-0.10799', '-0.14964', '-0.071959', '0.078407', '-0.045896', '-0.096546', '-0.21134', '-0.14044', '-0.0080023', '-0.17462', '0.07987', '0.026433', '-0.14563', '0.18325', '-0.038729', '0.19963', '0.078585', '0.19276', '0.076301', '-0.046172', '-0.065828', '0.031749', '0.11662', '0.063325', '0.057997', '0.13428', '-0.079557', '0.058755', '-0.14983', '-0.043233', '0.075283', '0.02032', '0.12484', '0.024488', '-0.0675', '0.1149', '0.079655', '-0.089283', '0.12662', '0.17913', '-0.051633', '0.013633', '0.058806', '0.087344', '0.033554', '0.21881', '-0.15916', '-0.026659', '0.0088207', '0.10708', '-0.20288', '0.24368', '0.033522', '0.12703', '0.14015', '0.050252', '-0.07739', '0.20909', '0.028045', '-0.043852', '-0.1886', '-0.17285', '0.09023', '-0.064943', '0.097711', '-0.066854', '0.026378', '-0.12376', '0.043199', '0.0040094', '0.091241', '-0.016021', '0.049839', '0.051762', '0.092562', '0.067835', '0.060233', '-0.054425', '-0.094497', '-0.090933', '0.18325', '-0.30752', '0.025016', '-0.030691', '0.12292', '-0.0039144']\n",
      "['.', '-0.12242', '0.0037909', '0.010159', '-0.098483', '0.043548', '0.18552', '-0.10094', '0.025914', '-0.055433', '0.13268', '0.34936', '0.24007', '0.24062', '0.19463', '0.05174', '0.0088705', '-0.074938', '-0.23811', '0.11645', '0.276', '0.19201', '0.12624', '-0.13421', '-0.11953', '-0.10103', '-0.069271', '-0.27658', '0.070833', '0.022786', '-0.055292', '0.12138', '-0.094049', '0.085966', '-0.011803', '-0.072119', '0.025245', '-0.1342', '-0.3815', '0.1644', '-0.27569', '0.16147', '-0.082476', '0.049343', '-0.076491', '0.18558', '-0.14286', '0.022327', '0.010158', '-0.1443', '-0.075945', '0.057789', '0.012489', '-0.12954', '0.13579', '0.29856', '-0.063521', '0.057713', '0.069595', '0.0904', '-0.070122', '0.12771', '-0.13629', '0.097142', '0.2016', '0.13168', '0.1151', '0.1242', '0.057562', '0.072408', '0.084348', '0.083224', '0.088738', '0.0057446', '-0.17799', '-0.12408', '-0.029613', '0.10363', '0.024142', '0.24391', '0.033293', '0.029553', '-0.099284', '0.051433', '-0.1903', '0.096788', '-0.31902', '-0.1912', '0.25297', '-0.15397', '0.052258', '-0.17491', '-0.25127', '-0.12112', '-0.036872', '-0.28574', '-0.11243', '-0.055043', '-0.1169', '0.21277', '-0.36147', '-0.021424', '-0.036944', '-0.15462', '-0.25052', '0.19209', '-0.02667', '-0.26313', '-0.075144', '0.0065444', '0.14508', '0.11344', '-0.032768', '-0.16691', '0.05488', '0.22072', '0.18219', '-0.060726', '0.17402', '-0.063773', '0.013431', '-0.0096867', '-0.19715', '-0.15394', '-0.13821', '0.095861', '0.034988', '0.092451', '0.082451', '0.36304', '0.20394', '0.1013', '-0.013031', '-0.25505', '-0.13833', '0.0094997', '0.098864', '-0.1898', '-0.032623', '0.12623', '-0.025513', '-0.00046524', '-0.16128', '0.065846', '0.28408', '-0.036319', '-0.036139', '-0.30768', '0.10096', '-0.056674', '-0.28152', '-0.011158', '-0.13399', '-0.0032681', '0.029126', '-0.0047312', '0.18286', '0.054', '-0.26489', '0.0026505', '0.21514', '-0.084325', '0.022779', '-0.0033443', '0.050553', '-0.017832', '0.067716', '0.10908', '0.12646', '-0.038435', '-0.0063813', '-0.15719', '-0.081733', '0.0087302', '0.040234', '0.22957', '-0.15839', '-0.17663', '0.0575', '0.067596', '0.028392', '-0.042361', '-0.048649', '-0.13024', '0.084102', '-0.2207', '0.020669', '0.13754', '0.070435', '0.11433', '-0.028175', '-0.012639', '-0.097399', '0.12377', '0.0058313', '-0.11522', '-0.088995', '-0.1896', '-0.18427', '-0.066709', '0.11876', '-0.11341', '-0.20342', '0.3031', '0.088259', '0.37172', '-0.050884', '0.017547', '-0.07717', '0.1462', '-0.030397', '-0.21688', '-0.24038', '-0.054892', '0.086128', '-0.017375', '-0.10724', '-0.15018', '0.042388', '0.046005', '0.0078496', '-0.1706', '-0.0040333', '0.12798', '-0.15603', '-0.090591', '0.012935', '-0.062826', '0.09037', '-0.010422', '0.17227', '0.051179', '0.3883', '0.0085175', '0.11158', '-0.061258', '-0.018145', '0.059499', '-0.011877', '0.071934', '0.098871', '-0.18242', '-0.033878', '-0.17143', '-0.11283', '0.040818', '-0.17687', '0.010729', '-0.22909', '0.028496', '0.093215', '-0.13807', '-0.021917', '-0.040867', '0.090828', '0.026745', '0.15675', '-0.090255', '-0.0073411', '-0.012366', '0.11263', '-0.15368', '-0.033303', '0.08637', '0.05027', '-0.086992', '0.12627', '0.11806', '-0.0016813', '0.21327', '0.11757', '-0.18669', '-0.10699', '0.052299', '0.047502', '-0.079123', '-0.27735', '-0.061187', '0.035106', '-0.050265', '0.026791', '-0.14013', '-0.11489', '-0.11702', '0.036767', '0.095714', '0.14562', '0.024209', '0.31236', '0.054329', '-0.0025081', '0.12909', '0.066951', '0.079795', '-0.0071078', '0.13425', '-0.14922', '0.10463', '-0.017005', '0.030068', '0.21763']\n"
     ]
    }
   ],
   "source": [
    "i = 1\n",
    "for o in open(EMBEDDING_FILE):\n",
    "    i += 1\n",
    "    print(o.strip().split())\n",
    "    if i == 5:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_lgb(train_X, train_y, val_X, val_y, test_X):\n",
    "    params = {\n",
    "        \"objective\" : \"regression\",\n",
    "        \"metric\" : \"rmse\",\n",
    "        \"num_leaves\" : 30,\n",
    "        \"learning_rate\" : 0.1,\n",
    "        \"bagging_fraction\" : 0.7,\n",
    "        \"feature_fraction\" : 0.7,\n",
    "        \"bagging_frequency\" : 5,\n",
    "        \"bagging_seed\" : 2018,\n",
    "        \"verbosity\" : -1\n",
    "    }\n",
    "    \n",
    "    lgtrain = lgb.Dataset(train_X, label=train_y)\n",
    "    lgval = lgb.Dataset(val_X, label=val_y)\n",
    "    evals_result = {}\n",
    "    model = lgb.train(params, lgtrain, 1000, valid_sets=[lgval], early_stopping_rounds=100, verbose_eval=20, evals_result=evals_result)\n",
    "    \n",
    "    pred_test_y = model.predict(test_X, num_iteration=model.best_iteration)\n",
    "    return pred_test_y, model, evals_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1303424, 12) (200000, 12) (508438, 12)\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[20]\tvalid_0's rmse: 0.236221\n",
      "[40]\tvalid_0's rmse: 0.233507\n",
      "[60]\tvalid_0's rmse: 0.232136\n",
      "[80]\tvalid_0's rmse: 0.231493\n",
      "[100]\tvalid_0's rmse: 0.231028\n",
      "[120]\tvalid_0's rmse: 0.230668\n",
      "[140]\tvalid_0's rmse: 0.230338\n",
      "[160]\tvalid_0's rmse: 0.230086\n",
      "[180]\tvalid_0's rmse: 0.229867\n",
      "[200]\tvalid_0's rmse: 0.22968\n",
      "[220]\tvalid_0's rmse: 0.229557\n",
      "[240]\tvalid_0's rmse: 0.2294\n",
      "[260]\tvalid_0's rmse: 0.229287\n",
      "[280]\tvalid_0's rmse: 0.229155\n",
      "[300]\tvalid_0's rmse: 0.229047\n",
      "[320]\tvalid_0's rmse: 0.228926\n",
      "[340]\tvalid_0's rmse: 0.228818\n",
      "[360]\tvalid_0's rmse: 0.228743\n",
      "[380]\tvalid_0's rmse: 0.228671\n",
      "[400]\tvalid_0's rmse: 0.22859\n",
      "[420]\tvalid_0's rmse: 0.228505\n",
      "[440]\tvalid_0's rmse: 0.228418\n",
      "[460]\tvalid_0's rmse: 0.228355\n",
      "[480]\tvalid_0's rmse: 0.228291\n",
      "[500]\tvalid_0's rmse: 0.228261\n",
      "[520]\tvalid_0's rmse: 0.22821\n",
      "[540]\tvalid_0's rmse: 0.22815\n",
      "[560]\tvalid_0's rmse: 0.228073\n",
      "[580]\tvalid_0's rmse: 0.228022\n",
      "[600]\tvalid_0's rmse: 0.227969\n",
      "[620]\tvalid_0's rmse: 0.227926\n",
      "[640]\tvalid_0's rmse: 0.227887\n",
      "[660]\tvalid_0's rmse: 0.227844\n",
      "[680]\tvalid_0's rmse: 0.227804\n",
      "[700]\tvalid_0's rmse: 0.227766\n",
      "[720]\tvalid_0's rmse: 0.227738\n",
      "[740]\tvalid_0's rmse: 0.22771\n",
      "[760]\tvalid_0's rmse: 0.227664\n",
      "[780]\tvalid_0's rmse: 0.227633\n",
      "[800]\tvalid_0's rmse: 0.227592\n",
      "[820]\tvalid_0's rmse: 0.22755\n",
      "[840]\tvalid_0's rmse: 0.227526\n",
      "[860]\tvalid_0's rmse: 0.227489\n",
      "[880]\tvalid_0's rmse: 0.227456\n",
      "[900]\tvalid_0's rmse: 0.227423\n",
      "[920]\tvalid_0's rmse: 0.227385\n",
      "[940]\tvalid_0's rmse: 0.227356\n",
      "[960]\tvalid_0's rmse: 0.22732\n",
      "[980]\tvalid_0's rmse: 0.227303\n",
      "[1000]\tvalid_0's rmse: 0.227271\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\tvalid_0's rmse: 0.227271\n"
     ]
    }
   ],
   "source": [
    "# Splitting the data for model training#\n",
    "dev_X = train_X.iloc[:-200000,:]\n",
    "val_X = train_X.iloc[-200000:,:]\n",
    "dev_y = train_y[:-200000]\n",
    "val_y = train_y[-200000:]\n",
    "print(dev_X.shape, val_X.shape, test_X.shape)\n",
    "\n",
    "# Training the model #\n",
    "pred_test, model, evals_result = run_lgb(dev_X, dev_y, val_X, val_y, test_X)\n",
    "\n",
    "# Making a submission file #\n",
    "pred_test[pred_test>1] = 1\n",
    "pred_test[pred_test<0] = 0\n",
    "sub_df = pd.DataFrame({\"item_id\":test_id})\n",
    "sub_df[\"deal_probability\"] = pred_test\n",
    "sub_df.to_csv(\"baseline_lgb.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
